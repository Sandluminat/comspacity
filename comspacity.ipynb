{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Comspacity***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Language and Text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"english\"\n",
    "text = \"Hello. My name is Sandro. This should work.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load language model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded spacy model for english\n",
      "Hello. My name is Sandro. This should work.\n"
     ]
    }
   ],
   "source": [
    "if language == \"english\":\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "elif language == \"german\":\n",
    "    nlp = spacy.load(\"de_core_news_sm\")\n",
    "doc = nlp(text)\n",
    "print(f\"Loaded spacy model for {language}.\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Variables and open sample.json for word frequency**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = 0\n",
    "words_length = 0\n",
    "verbes = 0\n",
    "hard_words = 0\n",
    "sentences = 0\n",
    "sentences_list = []\n",
    "with open('sample.json', 'r') as openfile:\n",
    "        json_object = json.load(openfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Counting variables over whole text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 32\n",
      "Words length of all words: 132\n",
      "Number of verbes: 4\n",
      "Number of hard_words: 4\n",
      "Number of sentences: 12\n"
     ]
    }
   ],
   "source": [
    "for line in doc.sents:\n",
    "        for token in line:\n",
    "                if spacy.explain(token.pos_) != \"punctuation\" and token.lemma_ != \" \" and \"http\" not in token.lemma_:\n",
    "                        words += 1\n",
    "                        words_length += len(token)\n",
    "\n",
    "                        if token.pos_ == \"VERB\":\n",
    "                                verbes += 1\n",
    "\n",
    "                        if token.lower_ in json_object:\n",
    "                                pass\n",
    "                        else:\n",
    "                                hard_words += 1\n",
    "                                \n",
    "                if spacy.explain(token.tag_) == \"punctuation mark, sentence closer\" or spacy.explain(token.tag_) == \"sentence-final punctuation mark\":\n",
    "                        sentences += 1\n",
    "print(f\"Number of words: {words}\")\n",
    "print(f\"Words length of all words: {words_length}\")\n",
    "print(f\"Number of verbes: {verbes}\")\n",
    "print(f\"Number of hard_words: {hard_words}\")\n",
    "print(f\"Number of sentences: {sentences}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Counting Variables per sentencec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "The sentence: 'Hello.' has 1 words, 0 verbes and 0 hardwords. The combined word length is 5.\n",
      "True\n",
      "The sentence: 'My name is Sandro.' has 4 words, 0 verbes and 1 hardwords. The combined word length is 14.\n",
      "True\n",
      "The sentence: 'This should work.' has 3 words, 1 verbes and 0 hardwords. The combined word length is 14.\n"
     ]
    }
   ],
   "source": [
    "for line in doc.sents:\n",
    "        sentence = line.text\n",
    "        for token in line:\n",
    "                if spacy.explain(token.pos_) != \"punctuation\" and token.lemma_ != \" \" and \"http\" not in token.lemma_:\n",
    "                        words += 1\n",
    "                        words_length += len(token)\n",
    "\n",
    "                        if token.pos_ == \"VERB\":\n",
    "                                verbes += 1\n",
    "\n",
    "                        if token.lower_ in json_object:\n",
    "                                pass\n",
    "                        else:\n",
    "                                hard_words += 1\n",
    "                    \n",
    "                if spacy.explain(token.tag_) == \"punctuation mark, sentence closer\" or spacy.explain(token.tag_) == \"sentence-final punctuation mark\":\n",
    "                        print(True)\n",
    "                        x = [sentence, words, words_length, verbes, hard_words]\n",
    "                        print(f\"The sentence: '{sentence}' has {words} words, {verbes} verbes and {hard_words} hardwords. The combined word length is {words_length}.\")\n",
    "                        sentences_list.append(x)\n",
    "                        # Resetting variables\n",
    "                        words = 0\n",
    "                        words_length = 0\n",
    "                        verbes = 0\n",
    "                        hard_words = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**calculate variables to get text-complexity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average word length: 4.125\n",
      "average hard words: 0.125\n",
      "average verbes per sentence: 0.3333333333333333\n",
      "average words per sentence: 2.6666666666666665\n"
     ]
    }
   ],
   "source": [
    "try:    \n",
    "    average_word_length = words_length/words\n",
    "    average_hard_words = hard_words/words\n",
    "except:\n",
    "    average_word_length = 0\n",
    "    average_hard_words = 0\n",
    "try:\n",
    "    verbes_per_sentence = verbes/sentences\n",
    "    words_per_sentence = words/sentences\n",
    "except:\n",
    "    verbes_per_sentence = 0\n",
    "    words_per_sentence = 0\n",
    "\n",
    "print(f\"average word length: {average_word_length}\")\n",
    "print(f\"average hard words: {average_hard_words}\")\n",
    "print(f\"average verbes per sentence: {verbes_per_sentence}\")\n",
    "print(f\"average words per sentence: {words_per_sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set weights to calculate text-complexity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if language == \"english\":\n",
    "    sentence_length_weight = 2\n",
    "    average_verbes_weight = 7\n",
    "    word_length_weight = 12\n",
    "    average_hard_words_weight = 10\n",
    "elif language == \"german\":\n",
    "    sentence_length_weight = 2\n",
    "    average_verbes_weight = 7\n",
    "    word_length_weight = 11\n",
    "    average_hard_words_weight = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get text-complexity.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58.416666666666664\n"
     ]
    }
   ],
   "source": [
    "complexity_of_text = words_per_sentence*sentence_length_weight + verbes_per_sentence*average_verbes_weight + \\\n",
    "                        average_word_length*word_length_weight + average_hard_words*average_hard_words_weight\n",
    "print(complexity_of_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a4c1ca8fe20c5b23d5624becb66a25f8280d4019d6b086166a4fbe6f47efd13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
