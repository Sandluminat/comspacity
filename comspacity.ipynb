{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Comspacity***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Language and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"english\"\n",
    "text = \"Hello. This is a sample text. You can write in here whatever you want.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load language model and set weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded spacy model for english.\n",
      "Hello. This is a sample text. You can write in here whatever you want.\n"
     ]
    }
   ],
   "source": [
    "if language == \"english\":\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    sentence_length_weight = 2\n",
    "    average_verbes_weight = 7\n",
    "    word_length_weight = 12\n",
    "    average_hard_words_weight = 10\n",
    "\n",
    "elif language == \"german\":\n",
    "    nlp = spacy.load(\"de_core_news_sm\")\n",
    "    \n",
    "    sentence_length_weight = 2\n",
    "    average_verbes_weight = 7\n",
    "    word_length_weight = 11\n",
    "    average_hard_words_weight = 0\n",
    "\n",
    "\n",
    "doc = nlp(text)\n",
    "print(f\"Loaded spacy model for {language}.\")\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complexity of text**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Variables and open sample.json for word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = 0\n",
    "words_length = 0\n",
    "verbes = 0\n",
    "hard_words = 0\n",
    "sentences = 0\n",
    "with open('./backend/sample.json', 'r') as openfile:\n",
    "        json_object = json.load(openfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting variables over whole text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: 14\n",
      "Words length of all words: 54\n",
      "Number of verbes: 2\n",
      "Number of hard_words: 0\n",
      "Number of sentences: 3\n"
     ]
    }
   ],
   "source": [
    "for line in doc.sents:\n",
    "        for token in line:\n",
    "                if spacy.explain(token.pos_) != \"punctuation\" and token.lemma_ != \" \" and \"http\" not in token.lemma_:\n",
    "                        words += 1\n",
    "                        words_length += len(token)\n",
    "\n",
    "                        if token.pos_ == \"VERB\":\n",
    "                                verbes += 1\n",
    "\n",
    "                        if token.lower_ in json_object:\n",
    "                                pass\n",
    "                        else:\n",
    "                                hard_words += 1\n",
    "                                \n",
    "                if spacy.explain(token.tag_) == \"punctuation mark, sentence closer\" or spacy.explain(token.tag_) == \"sentence-final punctuation mark\":\n",
    "                        sentences += 1\n",
    "print(f\"Number of words: {words}\")\n",
    "print(f\"Words length of all words: {words_length}\")\n",
    "print(f\"Number of verbes: {verbes}\")\n",
    "print(f\"Number of hard_words: {hard_words}\")\n",
    "print(f\"Number of sentences: {sentences}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate variables to get text-complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average word length: 3.857142857142857\n",
      "average hard words: 0.0\n",
      "average verbes per sentence: 0.6666666666666666\n",
      "average words per sentence: 4.666666666666667\n"
     ]
    }
   ],
   "source": [
    "try:    \n",
    "    average_word_length = words_length/words\n",
    "    average_hard_words = hard_words/words\n",
    "except:\n",
    "    average_word_length = 0\n",
    "    average_hard_words = 0\n",
    "try:\n",
    "    verbes_per_sentence = verbes/sentences\n",
    "    words_per_sentence = words/sentences\n",
    "except:\n",
    "    verbes_per_sentence = 0\n",
    "    words_per_sentence = 0\n",
    "\n",
    "print(f\"average word length: {average_word_length}\")\n",
    "print(f\"average hard words: {average_hard_words}\")\n",
    "print(f\"average verbes per sentence: {verbes_per_sentence}\")\n",
    "print(f\"average words per sentence: {words_per_sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get text-complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This text has a complexity score of 60.285714285714285\n"
     ]
    }
   ],
   "source": [
    "complexity_of_text = words_per_sentence*sentence_length_weight + verbes_per_sentence*average_verbes_weight + \\\n",
    "                        average_word_length*word_length_weight + average_hard_words*average_hard_words_weight\n",
    "print(f\"This text has a complexity score of {complexity_of_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complexity per sentence**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Variables and open sample.json for word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = 0\n",
    "words_length = 0\n",
    "verbes = 0\n",
    "hard_words = 0\n",
    "sentences_list = []\n",
    "with open('./backend/sample.json', 'r') as openfile:\n",
    "        json_object = json.load(openfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting Variables per sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence: 'Hello.' has 1 words, 0 verbes and 0 hardwords. The combined word length is 5.\n",
      "The sentence: 'This is a sample text.' has 5 words, 0 verbes and 0 hardwords. The combined word length is 17.\n",
      "The sentence: 'You can write in here whatever you want.' has 8 words, 2 verbes and 0 hardwords. The combined word length is 32.\n"
     ]
    }
   ],
   "source": [
    "for line in doc.sents:\n",
    "        sentence = line.text\n",
    "        for token in line:\n",
    "                if spacy.explain(token.pos_) != \"punctuation\" and token.lemma_ != \" \" and \"http\" not in token.lemma_:\n",
    "                        words += 1\n",
    "                        words_length += len(token)\n",
    "\n",
    "                        if token.pos_ == \"VERB\":\n",
    "                                verbes += 1\n",
    "\n",
    "                        if token.lower_ in json_object:\n",
    "                                pass\n",
    "                        else:\n",
    "                                hard_words += 1\n",
    "                    \n",
    "                if spacy.explain(token.tag_) == \"punctuation mark, sentence closer\" or spacy.explain(token.tag_) == \"sentence-final punctuation mark\":\n",
    "                        x = [sentence, words, words_length, verbes, hard_words]\n",
    "                        print(f\"The sentence: '{sentence}' has {words} words, {verbes} verbes and {hard_words} hardwords. The combined word length is {words_length}.\")\n",
    "                        sentences_list.append(x)\n",
    "                        # Resetting variables\n",
    "                        words = 0\n",
    "                        words_length = 0\n",
    "                        verbes = 0\n",
    "                        hard_words = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate variables to get text complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence: 'Hello.' has an average word-length of 5.0 and an average of 0.0 hard words per sentence\n",
      "The sentence: 'This is a sample text.' has an average word-length of 3.4 and an average of 0.0 hard words per sentence\n",
      "The sentence: 'You can write in here whatever you want.' has an average word-length of 4.0 and an average of 0.0 hard words per sentence\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences_list:\n",
    "    try:    \n",
    "        average_word_length = sentence[2]/sentence[1]\n",
    "        average_hard_words = sentence[4]/sentence[1]\n",
    "    except:\n",
    "        average_word_length = 0\n",
    "        average_hard_words = 0\n",
    "    \n",
    "    sentence[2] = average_word_length\n",
    "    sentence[4] = average_hard_words\n",
    "    print(f\"The sentence: '{sentence[0]}' has an average word-length of {sentence[2]} and an average of {sentence[4]} hard words per sentence\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get text-complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence: 'Hello.' has a text-complexity score of 62.0\n",
      "The sentence: 'This is a sample text.' has a text-complexity score of 50.8\n",
      "The sentence: 'You can write in here whatever you want.' has a text-complexity score of 78.0\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences_list:\n",
    "    complexity_of_text = sentence[1]*sentence_length_weight + sentence[3]*average_verbes_weight + \\\n",
    "                        sentence[2]*word_length_weight + sentence[4]*average_hard_words_weight\n",
    "    print(f\"The sentence: '{sentence[0]}' has a text-complexity score of {complexity_of_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a4c1ca8fe20c5b23d5624becb66a25f8280d4019d6b086166a4fbe6f47efd13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
